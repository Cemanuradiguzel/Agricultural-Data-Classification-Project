# -*- coding: utf-8 -*-
"""LandType.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HEdNnyTk2ovWM6Owvyt9C30mmm92vwFW
"""

import numpy as np
import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import MinMaxScaler

df=pd.read_excel('Data_processed.xlsx')
df_=pd.read_excel('Original_Data.xls')

df

missing_values = df.isnull().sum()

missing_categories = missing_values[missing_values > 0]

print("Boş değerleri olan kategoriler:\n", missing_categories)

# Clean up spaces and incorrect characters
df['Longitude'] = df['Longitude'].astype(str)  # Convert data to string
df['Longitude'] = df['Longitude'].str.replace(r'[^\d\.\-]', '', regex=True) # Remove everything other than numbers and periods
df['Longitude'] = pd.to_numeric(df['Longitude'], errors='coerce')  # String to float, make errors NaN

mean_longitude = df['Longitude'].mean()
df['Longitude'].fillna(mean_longitude)

# Fill missing values using the previous valid value
missing_variables = ["HerbicideYear","HerbicideMonth", "HerbicideWeekNum"]
missing_columns_in_dataset = [col for col in df.columns if col in missing_variables]

for col in missing_columns_in_dataset:
    df[col] = df[col].ffill()

# Initialize KNNImputer with 5 nearest neighbors for imputing missing values
missing1_variables =["HerbicideDay","DaysFromSowingToHerbicide","DaysFromHerbicideToHarvest"]
missing1_columns_in_dataset = [col for col in df.columns if col in missing1_variables]

imputer = KNNImputer(n_neighbors=5)
df[missing1_columns_in_dataset] = imputer.fit_transform(df[missing1_columns_in_dataset])

for col in missing1_columns_in_dataset:
    # Convert the column values to numeric, coercing invalid entries to NaN
    df[col] = pd.to_numeric(df[col], errors='coerce')
    # Fill NaN values with 0
    df[col] = df[col].fillna(0).astype(int)

missing_values = df.isnull().sum()

missing_categories = missing_values[missing_values > 0]

print("Boş değerleri olan kategoriler:\n", missing_categories)

# To improve performance, we converted everything to numeric and normalized values between 0 and 1
scaler = MinMaxScaler()

columns_to_scale = df.columns[df.columns.get_loc('Longitude'):df.columns.get_loc('DaysFromHerbicideToHarvest') + 1]
df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])

import matplotlib.pyplot as plt

# Count the occurrences of each category in 'LandType'
landtype_counts = df_['LandType'].value_counts()

# Plot the distribution as a bar chart
landtype_counts.plot(kind='bar')
plt.title("Distribution of LandType")
plt.xlabel("LandType Categories")
plt.ylabel("Count")
plt.show()

df['GrainYield']=df['GrainYield'].map({'A':0,'B':1,'C':2})
Y = df['GrainYield'].to_numpy()

for col in df.columns:
    # Eğer sütun sayısal değilse
    if df[col].dtype != 'int64' and df[col].dtype != 'float64':
        # Sütunu sayısal hale getirmeye çalışın, hataları NaN olarak değiştirin
        df[col] = pd.to_numeric(df[col], errors='coerce')

df

# Filter Lowland and MediumLand rows into two separate DataFrames
df_lowland = df[df["LandType_Lowland"] == 1].copy()
df_lowland = df_lowland.drop(columns=['LandType_Lowland', 'LandType_MediumLand', 'LandType_Upland'])
df_lowland['LandType'] = 'Lowland'

df_mediumland = df[df["LandType_MediumLand"] == 1].copy()
df_mediumland = df_mediumland.drop(columns=['LandType_Lowland', 'LandType_MediumLand', 'LandType_Upland'])

# Optional: Check shapes
print("Lowland rows:", df_lowland.shape)
print("MediumLand rows:", df_mediumland.shape)
df_mediumland['LandType'] = 'MediumLand'

# Combine the two DataFrames if needed
df_combined = pd.concat([df_lowland, df_mediumland])

# Plot the distribution of LandType after filtering
df_combined['LandType'].value_counts().plot(kind='bar')
plt.title("Distribution of LandType (Filtered)")
plt.xlabel("LandType Categories")
plt.ylabel("Count")
plt.show()

import pandas as pd
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows

output_file = "data.xlsx"
wb = Workbook()
ws = wb.active
ws.title = "Data"

df_lowland_copy = df_lowland.copy()
df_combined_copy = df_combined.copy()
df_mediumland_copy= df_mediumland.copy()

ws.append(["lowland Data"])
for row in dataframe_to_rows(df_lowland_copy, index=False, header=True):
    ws.append(row)

ws.append([])

ws.append(["MediumLand Data"])
for row in dataframe_to_rows(df_mediumland_copy, index=False, header=True):
    ws.append(row)

wb.save(output_file)

missing_values = df_lowland.isnull().sum()

missing_categories = missing_values[missing_values > 0]

print("Boş değerleri olan kategoriler:\n", missing_categories)

missing_values = df_mediumland.isnull().sum()

missing_categories = missing_values[missing_values > 0]

print("Boş değerleri olan kategoriler:\n", missing_categories)

datasets = [df_mediumland, df_lowland]

for df in datasets:
    df['Longitude'] = df['Longitude'].astype(str)
    df['Longitude'] = df['Longitude'].str.replace(r'[^\d\.\-]', '', regex=True)
    df['Longitude'] = pd.to_numeric(df['Longitude'], errors='coerce')
    mean_longitude = df['Longitude'].mean()
    df['Longitude'] = df['Longitude'].fillna(mean_longitude)

for df in datasets:
  missing_values = df_mediumland.isnull().sum()
  missing_categories = missing_values[missing_values > 0]
  print("Boş değerleri olan kategoriler:\n", missing_categories)

from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef, roc_auc_score
import numpy as np
from sklearn.feature_selection import f_classif, SelectKBest
def evaluate_model(model, X, y, num_features=5):

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=53)
    results = []

    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        # Özellik seçimi
        f_values, p_values = f_classif(X, y)

        # Rank features based on F-values
        feature_ranks = np.argsort(f_values)[::-1]  # Sort in descending order

        # Select top k features based on rank
        k = 5  # Number of features to select
        selected_features = X.columns[feature_ranks[:k]]

        X_train_selected = X_train[selected_features]
        X_val_selected = X_val[selected_features]

        # Modelin eğitilmesi
        model.fit(X_train_selected, y_train)
        y_pred = model.predict(X_val_selected)


        # AUC hesabı için olasılıklar
        try:
            y_prob = model.predict_proba(X_val_selected)
            auc = roc_auc_score(y_val, y_prob, multi_class='ovr', average='weighted')
        except AttributeError:
            auc = None

        accuracy = accuracy_score(y_val, y_pred)
        f1 = f1_score(y_val, y_pred, average='weighted')
        precision = precision_score(y_val, y_pred, average='weighted')
        recall = recall_score(y_val, y_pred, average='weighted')
        mcc = matthews_corrcoef(y_val, y_pred)


        results.append({
            'Selected Features': selected_features,
            'Fold': fold + 1,
            'Accuracy': accuracy,
            'AUC': auc,
            'F1 Score': f1,
            'Precision': precision,
            'Recall': recall,
            'MCC': mcc,
        })

    avg_results = {
        'Accuracy': sum(r['Accuracy'] for r in results) / len(results),
        'AUC': sum(r['AUC'] for r in results) / len(results) if all(r['AUC'] is not None for r in results) else None,
        'F1 Score': sum(r['F1 Score'] for r in results) / len(results),
        'Precision': sum(r['Precision'] for r in results) / len(results),
        'Recall': sum(r['Recall'] for r in results) / len(results),
        'MCC': sum(r['MCC'] for r in results) / len(results),
    }

    return avg_results, results

import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier # Import necessary classes
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

models = [
    ('Decision Tree', DecisionTreeClassifier(max_depth=8,random_state=53)),
    ('Random Forest', RandomForestClassifier(n_estimators=50,bootstrap=True,random_state=53)),
    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=50, subsample=0.8, random_state=53)),
    ('AdaBoost', AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=53)),
    ('Extra Trees', ExtraTreesClassifier(n_estimators=100, max_depth=8, random_state=53)),
    ('SVC', SVC(C=0.5,kernel='linear', random_state=53)),

]

from sklearn.model_selection import GridSearchCV
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from imblearn.over_sampling import SMOTE

# Label Encoder tanımla
le = LabelEncoder()

# Datasetleri işle
for df in datasets:
    # Kategorik sütunları sayısal değerlere çevir
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = le.fit_transform(df[col])

    # Features (X) ve Target (Y)
    X = df.drop(columns=['GrainYield'])  # Hedef sütunu çıkar
    Y = df['GrainYield'].to_numpy()

    # Train-test split
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

    # Modelleri sırayla çalıştır
    for model_name, model in models:
        # Model eğitimi
        model.fit(X_train, Y_train)

        # Tahmin
        predictions = model.predict(X_test)

        # Performans değerlendirmesi
        accuracy = accuracy_score(Y_test, predictions)
        f1 = f1_score(Y_test, predictions, average='weighted')
        precision = precision_score(Y_test, predictions, average='weighted')
        recall = recall_score(Y_test, predictions, average='weighted')

        # Sonuçları yazdır
        print(f"Model: {model_name}")
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  F1 Score: {f1:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall: {recall:.4f}")
        print("-" * 30)

# Toplanan önemli özellikleri tutmak için bir liste
all_top_features = []

for model_name, model in models:
    if hasattr(model, 'feature_importances_'):  # Check if the model has feature_importances_
        feature_importances = model.feature_importances_
        importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
        importance_df = importance_df.sort_values(by='Importance', ascending=False)
        print(f"Feature Importances for {model_name}:\n{importance_df}\n")

        top_features = importance_df.head(30)
        all_top_features.extend(top_features['Feature'].tolist())  # Önemli özelliklerin isimlerini listeye ekle
    else:
        print(f"{model_name} does not have feature_importances_.\n")

# En çok tekrar eden özelliklere göre sıralama
from collections import Counter
top_features_final = [item for item, count in Counter(all_top_features).most_common(40)]

# Sonuçları yazdır
print(f"Top 40 Features across all models: {top_features_final}")

"""top_features = importance_df.sort_values(by='Importance', ascending=False).head(20)
print(top_features)"""

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

le = LabelEncoder()
i = 1

# datasets is likely a tuple. Convert to a list
datasets = list(datasets)  # convert tuple to list

for df in datasets:
    # Verinizi hazırlayın (Örnek: LandType ile CropType'ı tahmin etme)
    X = df[top_features['Feature']]  # Bağımsız değişkenler
    y = df['GrainYield']  # Bağımlı değişken

    print(f"For Dataset {i}:")
    i += 1
    # Veriyi eğitim ve test setlerine ayırın
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=53)

    imputer = SimpleImputer(strategy='mean')  # You can choose other strategies like 'median' or 'most_frequent'
    X_train = imputer.fit_transform(X_train)
    X_test = imputer.transform(X_test)

    smote = SMOTE(random_state=53)
    X_train, y_train = smote.fit_resample(X_train, y_train)

    for name, model in models:
        model.fit(X_train, y_train)  # Modeli eğit
        predictions = model.predict(X_test)  # Tahmin yap
        acc = accuracy_score(y_test, predictions)  # Doğruluk skoru hesapla
        print(f"{name} Accuracy: {acc:.4f}")
    print("\n")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Parametreler
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'max_features': ['sqrt', 'log2'],
    'min_samples_split': [2, 5, 10]
}

from sklearn.linear_model import LogisticRegression, SGDClassifier, PassiveAggressiveClassifier, RidgeClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.svm import SVC, LinearSVC, NuSVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import StratifiedKFold
import warnings

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

smote_variants = {
    "SMOTE": SMOTE(random_state=53, k_neighbors=10),
    "BorderlineSMOTE": BorderlineSMOTE(random_state=53, k_neighbors=10),
    "ADASYN": ADASYN(random_state=53)
}

le = LabelEncoder()
i=1

for df in datasets:
  print(f"For Dataset {i}:")
  i = i+1
  X = df[top_features['Feature']]  # Bağımsız değişkenler
  y = df['GrainYield']

  for smote_name, smote in smote_variants.items():
        print(f"\nUsing {smote_name}:")

        models = [
              ('Decision Tree', DecisionTreeClassifier(max_depth=8, random_state=53)),
              ('Random Forest', RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=53)),
              ('Gradient Boosting', GradientBoostingClassifier(n_estimators=50, subsample=0.8, random_state=53)),
              ('AdaBoost', AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=53)),
              ('Bagging Classifier', BaggingClassifier()),
              ('Extra Trees', ExtraTreesClassifier(n_estimators=100, max_depth=8, random_state=53)),
              ('K Neighbors', KNeighborsClassifier()),
              ('Radius Neighbors', RadiusNeighborsClassifier(radius=5)),
              ('SVC', SVC(probability=True)),
              ('Voting Classifier', VotingClassifier(estimators=[
                  ('rf', RandomForestClassifier(n_estimators=50, random_state=53)),
                  ('gb', GradientBoostingClassifier(n_estimators=50, random_state=53)),
                  ('svc', SVC(probability=True, random_state=53))
              ], voting='soft'))
          ]

          # Modelleri sırayla çalıştır
        for model_name, model in models:
              skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=53)
              fold_results = []

              for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):
                  # Veriyi eğitim ve test setine ayır
                  X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                  y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

                  smote = SMOTE(random_state=53)
                  X_train, y_train = smote.fit_resample(X_train, y_train)

                  # Modeli eğit ve tahmin yap
                  model.fit(X_train, y_train)
                  y_pred = model.predict(X_test)

                  # Performans değerlendirmesi
                  accuracy = accuracy_score(y_test, y_pred)
                  precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
                  recall = recall_score(y_test, y_pred, average='weighted')
                  f1 = f1_score(y_test, y_pred, average='weighted')

                  fold_results.append((accuracy, precision, recall, f1))

              # Katmanlar arası ortalama performans
              avg_accuracy = sum([res[0] for res in fold_results]) / len(fold_results)
              avg_precision = sum([res[1] for res in fold_results]) / len(fold_results)
              avg_recall = sum([res[2] for res in fold_results]) / len(fold_results)
              avg_f1 = sum([res[3] for res in fold_results]) / len(fold_results)


              # Sonuçları yazdır
              print(f"Model: {model_name}")
              print(f"  Average Accuracy: {avg_accuracy:.4f}")
              print(f"  Average Precision: {avg_precision:.4f}")
              print(f"  Average Recall: {avg_recall:.4f}")
              print(f"  Average F1 Score: {avg_f1:.4f}")
              print("-" * 30)
        print("\n")

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier
from sklearn.svm import SVC

# Modeller
models = [
    ('Decision Tree', DecisionTreeClassifier(max_depth=8, random_state=53)),
    ('Random Forest', RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=53)),
    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=50, subsample=0.8, random_state=53)),
    ('AdaBoost', AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=53)),
    ('Bagging Classifier', BaggingClassifier()),
    ('Extra Trees', ExtraTreesClassifier(n_estimators=100, max_depth=8, random_state=53)),
    ('K Neighbors', KNeighborsClassifier()),
    ('Radius Neighbors', RadiusNeighborsClassifier(radius=5)),
    ('SVC', SVC(probability=True))  # ROC için probability=True ekliyoruz
]
for df in datasets:
  # Örnek veri seti
  from sklearn.datasets import make_classification
  X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

  # Eğitim ve test setine ayırma
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

  # ROC grafiği çizimi
  plt.figure(figsize=(12, 8))

  for model_name, model in models:
      # Model eğitimi
      model.fit(X_train, y_train)

      # Tahmin edilen olasılıklar veya decision scores
      if hasattr(model, "predict_proba"):
          y_scores = model.predict_proba(X_test)[:, 1]
      elif hasattr(model, "decision_function"):
          y_scores = model.decision_function(X_test)
      else:
          print(f"{model_name} için ROC eğrisi çizilemiyor.")
          continue

      # ROC eğrisi için TPR ve FPR
      fpr, tpr, thresholds = roc_curve(y_test, y_scores)
      auc = roc_auc_score(y_test, y_scores)

      # ROC eğrisini çiz
      plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc:.2f})")

  # Rastgele tahmin çizgisi
  plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing (AUC = 0.50)")

  # Grafik düzenlemesi
  plt.xlabel("False Positive Rate")
  plt.ylabel("True Positive Rate")
  plt.title("ROC Curve Comparison")
  plt.legend(loc="lower right")
  plt.grid()
  plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
import numpy as np

# En iyi model için değerlendirme
best_model_name = None
best_model = None
best_accuracy = 0
best_predictions = None
for df in datasets:
  # Modelleri eğit ve doğruluklarını hesapla
  for model_name, model in models:
      # Model eğitimi
      model.fit(X_train, y_train)

      # Tahmin yap
      predictions = model.predict(X_test)

      # Doğruluk hesapla
      acc = accuracy_score(y_test, predictions)

      if acc > best_accuracy:
          best_accuracy = acc
          best_model_name = model_name
          best_model = model
          best_predictions = predictions

  # En iyi modelin Confusion Matrix'ini oluştur
  print(f"Best Model: {best_model_name} with Accuracy: {best_accuracy:.4f}")
  cm = confusion_matrix(y_test, best_predictions)

  # Confusion Matrix'i görselleştir
  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))
  disp.plot(cmap="Blues")
  plt.title(f"Confusion Matrix for {best_model_name}")
  plt.show()